
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mydomain.org/mysite/ntee/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%BA%BF%E6%80%A7%E6%8B%9F%E5%90%88%E5%AE%9E%E8%B7%B5/">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.4">
    
    
      
        <title>梯度下降线性拟合实践 - My Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.8608ea7d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="yellow" data-md-color-accent="pink">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#r" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="My Docs" class="md-header__button md-logo" aria-label="My Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            My Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              梯度下降线性拟合实践
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="My Docs" class="md-nav__button md-logo" aria-label="My Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    My Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    list
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            list
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../about/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Welcome/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contact
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xue01.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    test
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#r" class="md-nav__link">
    <span class="md-ellipsis">
      先把我之前用R拟合的代码列出来
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      下面进入正文
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      数据导入
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      数学基础
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      传统的梯度下降
    </span>
  </a>
  
    <nav class="md-nav" aria-label="传统的梯度下降">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      损失函数计算
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      梯度计算
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      迭代函数
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      激动人心的拟合计算
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      结果分析
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      随机梯度下降法
    </span>
  </a>
  
    <nav class="md-nav" aria-label="随机梯度下降法">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sgd" class="md-nav__link">
    <span class="md-ellipsis">
      单点SGD
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      展望
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>梯度下降线性拟合实践</h1>

<p>2024-10-16
- 前阵子刚学了这个算法，正好做实验有数据可以实践一下。报告里的拟合我用R语言弄的，都是别人写好的算法，这里我从头开始亲手拟合试一试。
- 本附录用的语言为python，环境为pycharm中的jupter-notebook插件，理论基础参见https://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes1.pdf</p>
<h4 id="r">先把我之前用R拟合的代码列出来</h4>
<pre><code class="language-R">library(readxl)
library(openxlsx)
setwd(&quot;/Users/liqingyu/Desktop/Excel\ data&quot;)  # 设置工作目录
data &lt;- read_excel(&quot;data1.xlsx&quot;)
df &lt;- lm(y ~ x, data=data)
summary(df)
#plot(model)
plot(data$x, data$y, main=&quot;distance-time graph&quot;, xlab=&quot;distance/cm&quot;, ylab=&quot;time/ms&quot;, pch=19)

# 添加拟合直线
abline(df, col=&quot;red&quot;, lwd=2)
</code></pre>
<h4 id="_1">下面进入正文</h4>
<pre><code class="language-python">import math,copy
import numpy as np
</code></pre>
<h3 id="_2">数据导入</h3>
<p>其实就两行数据直接输入就行，这里导入Excel尝试一下</p>
<pre><code class="language-python">import pandas as pd
df = pd.read_excel('/Users/liqingyu/Desktop/Excel data/data1.xlsx')
x = df['x']
y = df['y']
# 删去数据中的NaN值，用到了pandas
x,y = x.dropna(),y.dropna()
#将数据转化成数组
x = x.to_numpy()
y = y.to_numpy()
print(x)
print(y)
</code></pre>
<pre><code>[ 6.  8. 10. 12. 14. 16. 18. 20. 22. 24. 26.]
[0.03933333 0.05333333 0.06583333 0.08083333 0.09666667 0.11
 0.12166667 0.13666667 0.15       0.16333333 0.17666667]
</code></pre>
<h3 id="_3">数学基础</h3>
<p>先假设为线性模型，预测函数为$f_{w,b}(x^{(i)})$：
$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \tag{1}$$
损失函数$J(w,b)$计算公式：
$$J(w,b) = \frac{1}{2m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\tag{2}$$
传统的梯度下降：
$$\begin{align<em>} \text{ 重复至收敛:} \; \lbrace \newline
\;  w &amp;= w -  \alpha \frac{\partial J(w,b)}{\partial w} \tag{3}  \; \newline 
 b &amp;= b -  \alpha \frac{\partial J(w,b)}{\partial b}  \newline \rbrace
\end{align</em>}$$
参数 $w$, $b$ 需同时迭代。</p>
<p>梯度的具体计算：
$$
\begin{align}
\frac{\partial J(w,b)}{\partial w}  &amp;= \frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \tag{4}\
  \frac{\partial J(w,b)}{\partial b}  &amp;= \frac{1}{m} \sum\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \tag{5}\
\end{align}
$$</p>
<h3 id="_4">传统的梯度下降</h3>
<h4 id="_5">损失函数计算</h4>
<pre><code class="language-python">def compute_cost(x, y, w, b):
    # 获取数据容量
    m = x.shape[0] 
    cost = 0

    for i in range(m):
        f_wb = w * x[i] + b
        cost = cost + (f_wb - y[i])**2
    total_cost = 1 / (2 * m) * cost

    return total_cost
</code></pre>
<h4 id="_6">梯度计算</h4>
<pre><code class="language-python">def compute_gradient(x, y, w, b):    
    m = x.shape[0]
    #初始化
    dj_dw = 0
    dj_db = 0

    #这里每计算一次都要遍历一遍数据，每次下降精准但耗时较长
    for i in range(m):  
        f_wb = w * x[i] + b 
        dj_dw_i = (f_wb - y[i]) * x[i] 
        dj_db_i = f_wb - y[i] 
        dj_db += dj_db_i
        dj_dw += dj_dw_i 
    dj_dw = dj_dw / m 
    dj_db = dj_db / m 

    return dj_dw, dj_db
</code></pre>
<h4 id="_7">迭代函数</h4>
<pre><code class="language-python">def gradient_descent(x, y, w_in, b_in, alpha, num_iters, cost_function, gradient_function): 
    # w = copy.deepcopy(w_in) # 避免修改全局w_in
    # 记录历史数据分析用
    J_history = []
    p_history = []
    b = b_in
    w = w_in

    for i in range(num_iters):
        dj_dw, dj_db = gradient_function(x, y, w , b)     

        # 同时迭代b和w
        b = b - alpha * dj_db                            
        w = w - alpha * dj_dw                            

        # 记录J
        if i&lt;10000000:      # 差不多得了
            J_history.append( cost_function(x, y, w , b))
            p_history.append([w,b])
        # 间隔10%打印
        if i% math.ceil(num_iters/10) == 0:
            print(f&quot;Iteration {i:4}: Cost {J_history[-1]:0.2e} &quot;,
                  f&quot;dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  &quot;,
                  f&quot;w: {w: 0.6e}, b:{b: 0.6e}&quot;)

    return w, b, J_history, p_history 
</code></pre>
<h4 id="_8">激动人心的拟合计算</h4>
<pre><code class="language-python"># 参数初始化
w_init = 0
b_init = 0
# 调试参数
iterations = 100000
tmp_alpha = 1.0e-6
# 梯度下降运行
w_final, b_final, J_hist, p_hist = gradient_descent(x ,y, w_init, b_init, tmp_alpha, 
                                                    iterations, compute_cost, compute_gradient)
print(f&quot;(w,b) found by gradient descent: ({w_final:8.8f},{b_final:8.8f})&quot;)
</code></pre>
<pre><code>Iteration    0: Cost 6.87e-03  dj_dw: -2.017e+00, dj_db: -1.087e-01   w:  2.017091e-06, b: 1.087273e-07
Iteration 10000: Cost 2.08e-05  dj_dw: -1.036e-01, dj_db: -5.248e-03   w:  6.445964e-03, b: 3.450480e-04
Iteration 20000: Cost 2.71e-06  dj_dw: -5.338e-03, dj_db:  6.471e-05   w:  6.777041e-03, b: 3.594161e-04
Iteration 30000: Cost 2.66e-06  dj_dw: -2.921e-04, dj_db:  3.371e-04   w:  6.794222e-03, b: 3.568139e-04
Iteration 40000: Cost 2.66e-06  dj_dw: -3.303e-05, dj_db:  3.506e-04   w:  6.795285e-03, b: 3.533448e-04
Iteration 50000: Cost 2.66e-06  dj_dw: -1.970e-05, dj_db:  3.509e-04   w:  6.795520e-03, b: 3.498357e-04
Iteration 60000: Cost 2.66e-06  dj_dw: -1.899e-05, dj_db:  3.504e-04   w:  6.795712e-03, b: 3.463290e-04
Iteration 70000: Cost 2.66e-06  dj_dw: -1.893e-05, dj_db:  3.500e-04   w:  6.795901e-03, b: 3.428269e-04
Iteration 80000: Cost 2.65e-06  dj_dw: -1.890e-05, dj_db:  3.495e-04   w:  6.796090e-03, b: 3.393296e-04
Iteration 90000: Cost 2.65e-06  dj_dw: -1.888e-05, dj_db:  3.490e-04   w:  6.796279e-03, b: 3.358369e-04
(w,b) found by gradient descent: (0.00679647,0.00033235)
</code></pre>
<h4 id="_9">结果分析</h4>
<ul>
<li>一开始步长太大，cost函数发散，程序爆了；太小也不好，我定的迭代次数为100000次，测试发现1e-6最终损失值较小，1e-7损失反而大了需要增加迭代次数</li>
<li>斜率和R拟合的值比较接近（R为0.006890152），但是截距差挺多的，我又用卡西欧fx-991CN拟合截距约为-1.74e-03和R的结果相近，可能因为我的迭代次数还不够</li>
</ul>
<pre><code class="language-python">w_init = 0
b_init = 0
iterations = 10000000
tmp_alpha = 1.0e-5
w_final, b_final, J_hist, p_hist = gradient_descent(x, y, w_init, b_init, tmp_alpha,
                                                    iterations, compute_cost, compute_gradient)
print(f&quot;(w,b) found by gradient descent: ({w_final:8.8f},{b_final:8.8f})&quot;)
</code></pre>
<pre><code>Iteration    0: Cost 6.80e-03  dj_dw: -2.013e+00, dj_db: -1.086e-01   w:  2.012818e-05, b: 1.085758e-06
Iteration 1000000: Cost 4.38e-07  dj_dw: -3.851e-06, dj_db:  7.121e-05   w:  6.861572e-03, b:-1.138181e-03
Iteration 2000000: Cost 4.20e-07  dj_dw: -1.001e-06, dj_db:  1.851e-05   w:  6.882723e-03, b:-1.529307e-03
Iteration 3000000: Cost 4.19e-07  dj_dw: -2.601e-07, dj_db:  4.810e-06   w:  6.888221e-03, b:-1.630965e-03
Iteration 4000000: Cost 4.19e-07  dj_dw: -6.761e-08, dj_db:  1.250e-06   w:  6.889650e-03, b:-1.657387e-03
Iteration 5000000: Cost 4.19e-07  dj_dw: -1.757e-08, dj_db:  3.250e-07   w:  6.890021e-03, b:-1.664255e-03
Iteration 6000000: Cost 4.19e-07  dj_dw: -4.568e-09, dj_db:  8.446e-08   w:  6.890118e-03, b:-1.666040e-03
Iteration 7000000: Cost 4.19e-07  dj_dw: -1.187e-09, dj_db:  2.195e-08   w:  6.890143e-03, b:-1.666504e-03
Iteration 8000000: Cost 4.19e-07  dj_dw: -3.086e-10, dj_db:  5.706e-09   w:  6.890149e-03, b:-1.666624e-03
Iteration 9000000: Cost 4.19e-07  dj_dw: -8.021e-11, dj_db:  1.483e-09   w:  6.890151e-03, b:-1.666656e-03
(w,b) found by gradient descent: (0.00689015,-0.00166666)
</code></pre>
<p>我又把迭代次数加了100倍，步长相应加长了些，运行足足76s，截距和斜率都向R的结果靠近，斜率的值已经非常接近了。看来R和卡西欧用的应该不是这种算法，它们都是一瞬间完成的，还要准确的多。我下面用随机梯度下降法试试，应该会快一些。</p>
<h3 id="_10">随机梯度下降法</h3>
<h4 id="sgd">单点SGD</h4>
<p>每碰到一个点就计算一次梯度，有随机性但整体是收敛的，适用于大数据量情况，实际中更常用。这个小数据量内部大量随机取值应该也能达到效果。</p>
<pre><code class="language-python">def sgd(w, b, x, y, alpha, iterations):
    m = x.shape[0]
    J_hist = []
    p_hist = []

    for t in range(iterations):
        # 随机选择一个样本
        random_index = np.random.randint(m)
        x_i = x[random_index]
        y_i = y[random_index]

        # 计算梯度
        dj_dw = 2 * x_i * (x_i * w + b - y_i)
        dj_db = 2 * (x_i * w + b - y_i)
        # 更新参数
        w -= alpha * dj_dw
        b -= alpha * dj_db

        if t&lt;10000000:
            J_hist.append((w * x_i + b - y_i) ** 2 / (2))
            p_hist.append([w,b])
        # 间隔10%打印
        if t% math.ceil(iterations/10) == 0:
            print(f&quot;Iteration {t:4}: Cost {J_hist[-1]:0.2e} &quot;,
                  f&quot;dj_dw: {dj_dw: 0.3e}, dj_db: {dj_db: 0.3e}  &quot;,
                  f&quot;w: {w: 0.6e}, b:{b: 0.6e}&quot;)

    return w, b, J_hist, p_hist
</code></pre>
<pre><code class="language-python"># w = np.random.randn(1, 1)[0][0] # 随机初始化参数
# b = np.random.randn(1, 1)[0][0] # 注意原输出为数组
w = 0
b = 0
iterations = 10000000
tmp_alpha = 1.0e-5
w_final, b_final, J_hist1, p_hist1 = sgd(w, b, x, y, tmp_alpha, iterations)
print(f&quot;(w,b) found by gradient descent: ({w_final:8.8f},{b_final:8.8f})&quot;)
</code></pre>
<pre><code>Iteration    0: Cost 7.72e-04  dj_dw: -4.720e-01, dj_db: -7.867e-02   w:  4.720000e-06, b: 7.866667e-07
Iteration 1000000: Cost 1.03e-06  dj_dw:  2.871e-02, dj_db:  2.871e-03   w:  6.879212e-03, b:-1.526250e-03
Iteration 2000000: Cost 6.76e-08  dj_dw:  4.417e-03, dj_db:  7.361e-04   w:  6.892617e-03, b:-1.654578e-03
Iteration 3000000: Cost 9.22e-09  dj_dw:  2.175e-03, dj_db:  2.719e-04   w:  6.891841e-03, b:-1.665608e-03
Iteration 4000000: Cost 1.17e-08  dj_dw:  3.687e-03, dj_db:  3.073e-04   w:  6.887850e-03, b:-1.667678e-03
Iteration 5000000: Cost 1.50e-08  dj_dw:  4.171e-03, dj_db:  3.475e-04   w:  6.889270e-03, b:-1.664641e-03
Iteration 6000000: Cost 1.60e-06  dj_dw: -5.028e-02, dj_db: -3.591e-03   w:  6.896112e-03, b:-1.667515e-03
Iteration 7000000: Cost 1.08e-06  dj_dw: -4.723e-02, dj_db: -2.952e-03   w:  6.887534e-03, b:-1.668866e-03
Iteration 8000000: Cost 8.75e-08  dj_dw:  2.031e-02, dj_db:  8.463e-04   w:  6.892321e-03, b:-1.664104e-03
Iteration 9000000: Cost 3.32e-07  dj_dw:  4.293e-02, dj_db:  1.651e-03   w:  6.890429e-03, b:-1.670188e-03
(w,b) found by gradient descent: (0.00688775,-0.00166655)
</code></pre>
<p>随机梯度下降算法的优势显而易见。这里没办法用损失函数直接比较，因为本算法不需要把梯度求和再算损失函数，实际上算损失函数占据了主要算力。</p>
<p>但是我们可以将结果和R拟合的值进行比较，本算法同样迭代了一千万次，步长也一样，但是只用了21s，快了将近4倍。精确度方面不好比较，理论上参数合适的话应该是batch梯度下降更精确一些。</p>
<h3 id="_11">展望</h3>
<p>我了解实际应用中还有小批量梯度下降，介于单点和整体梯度下降之间。可惜我的时间实在不够了暂时搁置。本次讨论至少知道R语言和卡西欧计算器线性拟合不可能用的传统的batch梯度下降。其实还有一种正态方程线性拟合的方法，数学上非常优美，但是普适性不强，这里就不做比较了</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f1b6f286.min.js"></script>
      
        <script src="https://cdn.vercel-insights.com/v1/analytics.js"></script>
      
    
  </body>
</html>